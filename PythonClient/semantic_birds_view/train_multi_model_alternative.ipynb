{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_X_and_Y, get_data_gen, batcher, plot_semantic, make_movie\n",
    "\n",
    "\n",
    "DECIMATION = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "CAMERA_IDS = [\n",
    "    'FrontSS', 'LeftSS', 'RightSS', 'RearSS', 'TopSS'\n",
    "]\n",
    "\n",
    "CLASSES_NAMES = [\n",
    "    ['Roads', 'RoadLines'],\n",
    "    \n",
    "    ['Sidewalks'],\n",
    "    \n",
    "    ['Buildings'],\n",
    "    \n",
    "    ['Fences', 'Other', 'Pedestrians',\n",
    "     'Poles', 'Walls', 'TrafficSigns'],\n",
    "    \n",
    "    ['Vehicles'],\n",
    "    \n",
    "    ['Vegetation'],\n",
    "        \n",
    "    ['None']\n",
    "]\n",
    "\n",
    "\n",
    "# CLASSES_NAMES = [\n",
    "#     ['Roads', 'RoadLines'],\n",
    "    \n",
    "#     ['None', 'Buildings', 'Fences', 'Other', 'Pedestrians',\n",
    "#      'Poles', 'Walls', 'TrafficSigns',\n",
    "#      'Vegetation', 'Sidewalks'],\n",
    "    \n",
    "#     ['Vehicles'],\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "storage = get_X_and_Y(['Town01'], range(1), DECIMATION, CAMERA_IDS)\n",
    "X = [storage[id_] for id_ in CAMERA_IDS if 'Top' not in id_]\n",
    "Y = [storage[id_] for id_ in CAMERA_IDS if 'Top' in id_][0]\n",
    "print('\\nReading data took {:.2f} [s]'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = batcher(\n",
    "    get_data_gen(X, Y, classes_names=CLASSES_NAMES),\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_gen = batcher(\n",
    "    get_data_gen(X, Y, flip_prob=0.0, validation=False, classes_names=CLASSES_NAMES),\n",
    "    BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y, _ = next(train_gen)\n",
    "x, y = x_y[:3], x_y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x[0].shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Add, Subtract, Average, Flatten, Reshape, Dense, Input, Lambda, Concatenate, Softmax, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, Convolution2DTranspose\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "MACIEX_FILTER_SHAPE = (18, 12)\n",
    "\n",
    "\n",
    "def get_conv_encoder_model(\n",
    "    input_and_output_shape,\n",
    "    num_layers=4, central_exp=3,\n",
    "    act='elu', l2_reg=1e-3, inp_name=None,\n",
    "):\n",
    "    x = inp = Input(input_and_output_shape)\n",
    "\n",
    "    for i in range(num_layers, 0, -1):\n",
    "        x = Convolution2D(2**(central_exp+i), (3, 3), activation=act, padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        \n",
    "    encoder_name = 'encoder_submodel' if inp_name is None else 'encoder_submodel_'+inp_name\n",
    "    return Model(inp, x, name=encoder_name)\n",
    "    \n",
    "    \n",
    "def get_conv_decoder_model(\n",
    "    encoded_shape, output_shape,\n",
    "    num_layers=4, central_exp=3,\n",
    "    act='elu', l2_reg=1e-3, inp_name=None,\n",
    "):\n",
    "    x = inp = Input(encoded_shape)\n",
    "    \n",
    "    num_channels = output_shape[-1]\n",
    "    \n",
    "    x = Convolution2D(2**(central_exp+1), MACIEX_FILTER_SHAPE, activation=act, padding='same')(inp)\n",
    "    for i in range(1, num_layers+1):\n",
    "        x = Convolution2D(2**(central_exp+i), (3, 3), activation=act, padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        \n",
    "    x = Convolution2D(num_channels, (3, 3), activation='linear', padding='same')(x)\n",
    "\n",
    "    decoder_name = 'decoder_submodel' if inp_name is None else 'decoder_submodel_'+inp_name\n",
    "    return Model(inp, x, name=decoder_name)\n",
    "\n",
    "\n",
    "def get_alternative_multi_model(\n",
    "    input_shape, input_names,\n",
    "    num_ae_layers=4, central_ae_exp=3,\n",
    "    num_reconstruction_layers=3, central_reconstruction_exp=6,\n",
    "    act='elu', l2_reg=1e-3,\n",
    "):\n",
    "    inputs = {\n",
    "        inp_name: Input(input_shape, name='input_from_'+inp_name)\n",
    "        for inp_name in input_names\n",
    "    }\n",
    "\n",
    "    image_shape = input_shape[:2]\n",
    "    num_channels = input_shape[-1]\n",
    "    \n",
    "    encoder_models = {\n",
    "        inp_name: get_conv_encoder_model(input_shape, num_ae_layers,\n",
    "                                         central_ae_exp, act, l2_reg, inp_name)\n",
    "        for inp_name in input_names\n",
    "    }\n",
    "    encoded_shape = K.int_shape(encoder_models[input_names[0]].output)[1:]\n",
    "    \n",
    "    decoder_models = {\n",
    "        inp_name: get_conv_decoder_model(encoded_shape, input_shape,\n",
    "                                         num_ae_layers, central_ae_exp, act, l2_reg, inp_name)\n",
    "        for inp_name in input_names\n",
    "    }\n",
    "    \n",
    "    all_bottlenecks = {}\n",
    "    ae_outputs = {}\n",
    "    side_cameras = [camera_id for camera_id in CAMERA_IDS if 'Top' not in camera_id]\n",
    "    for_final_reconstruction = []\n",
    "    for inp_name in input_names:\n",
    "        inp = inputs[inp_name]\n",
    "        \n",
    "        bttlnck = encoder_models[inp_name](inp)\n",
    "        all_bottlenecks[inp_name] = bttlnck\n",
    "        if inp_name in side_cameras:\n",
    "            for_final_reconstruction.append(bttlnck)\n",
    "\n",
    "        decoded = decoder_models[inp_name](bttlnck)\n",
    "        ae_outputs[inp_name] = decoded\n",
    "        ae_outputs[inp_name] = Softmax(axis=3, name='decoded_from_'+inp_name)(ae_outputs[inp_name])\n",
    "        \n",
    "    x = Concatenate()(for_final_reconstruction)\n",
    "    encoded_reconstruction = Convolution2D(\n",
    "        encoded_shape[-1],\n",
    "        (3, 3),\n",
    "        activation=act,\n",
    "        padding='same',\n",
    "        name='before_reconstruction',\n",
    "    )(x)\n",
    "#     set_trace()\n",
    "                \n",
    "    encoded_diff = Subtract(name='encoded_from_TopSS-encoded_reconstruction')([all_bottlenecks['TopSS'], encoded_reconstruction])\n",
    "\n",
    "    reconstruction = decoder_models['TopSS'](encoded_reconstruction)\n",
    "    reconstruction = Softmax(axis=3, name='reconstruction')(reconstruction)\n",
    "    \n",
    "    outputs = (\n",
    "        [ae_outputs[inp_name] for inp_name in input_names]\n",
    "        + [reconstruction]\n",
    "        + [encoded_diff]\n",
    "    )\n",
    "    inputs = [inputs[inp_name] for inp_name in input_names]\n",
    "\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ae_layers = 3\n",
    "central_ae_exp = 5\n",
    "patience = 10\n",
    "num_sweeps = 24\n",
    "validation_episodes_for_movies = [100, 101]\n",
    "\n",
    "bottleneck_dim = (\n",
    "    BATCH_SIZE,\n",
    "    input_shape[0] // 2**num_ae_layers,\n",
    "    input_shape[1] // 2**num_ae_layers,\n",
    "    2**(central_ae_exp + 1),\n",
    ")\n",
    "\n",
    "zero_array = np.zeros(bottleneck_dim).astype('float32')\n",
    "\n",
    "alternative_multi_model = get_alternative_multi_model(\n",
    "    input_shape, CAMERA_IDS,\n",
    "    num_ae_layers, central_ae_exp,\n",
    "    num_reconstruction_layers=3, central_reconstruction_exp=6,\n",
    "    act='elu', l2_reg=1e-3,\n",
    ")\n",
    "alternative_multi_model.compile(\n",
    "    loss=6*['categorical_crossentropy'] + ['mse'],\n",
    "    loss_weights=5*[1] + [1] + [1],\n",
    "    optimizer=Adam(1e-4)\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_reconstruction_loss',\n",
    "    patience=patience,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "storage = get_X_and_Y(['Town01', 'Town02'], [100, 101], DECIMATION, CAMERA_IDS)\n",
    "X_val = [storage[id_] for id_ in CAMERA_IDS if 'Top' not in id_]\n",
    "Y_val = [storage[id_] for id_ in CAMERA_IDS if 'Top' in id_][0]\n",
    "valid_gen = batcher(\n",
    "    get_data_gen(X_val, Y_val, flip_prob=0.0, val_part=1, validation=True, classes_names=CLASSES_NAMES),\n",
    "    BATCH_SIZE,\n",
    "    zero_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "alternative_multi_model = load_model('models/alternative_multi_model__sweep=13_decimation=2_numclasses=7_valloss=0.325.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MULTI_MODEL_EPISODES = [\n",
    "    range(0, 8),\n",
    "    range(8, 16),\n",
    "    range(16, 24),\n",
    "    range(24, 32),\n",
    "    range(32, 40),\n",
    "]\n",
    "\n",
    "# I've also tried our a recurrent model, for which I used\n",
    "# a disjoint set of episodes (see the `recur_model.ipynb` for details)\n",
    "RECURRENT_EPISODES = [\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "for sweep in range(14, num_sweeps):\n",
    "    histories = []\n",
    "    if sweep % 6 == 0:\n",
    "        alternative_multi_model.optimizer = Adam(1e-4)\n",
    "        \n",
    "    for episodes in MULTI_MODEL_EPISODES:\n",
    "        start_time = time.time()\n",
    "        storage = get_X_and_Y(['Town01', 'Town02'], episodes, DECIMATION, CAMERA_IDS, storage)\n",
    "        X = [storage[id_] for id_ in CAMERA_IDS if 'Top' not in id_]\n",
    "        Y = [storage[id_] for id_ in CAMERA_IDS if 'Top' in id_][0]\n",
    "        print('\\nReading data took {:.2f} [s]'.format(time.time() - start_time))\n",
    "\n",
    "        train_gen = batcher(\n",
    "            get_data_gen(X, Y, val_part=10**10, classes_names=CLASSES_NAMES),\n",
    "            BATCH_SIZE,\n",
    "            zero_array,\n",
    "        )\n",
    "        \n",
    "        x_y, _ = next(train_gen)\n",
    "        one_batch_X, one_batch_Y = x_y[:4], x_y[4]\n",
    "\n",
    "        preds = alternative_multi_model.predict(one_batch_X + [one_batch_Y])\n",
    "        preds = [pred[0:1] for pred in preds]\n",
    "\n",
    "        for j, x in enumerate([x[0:1] for x in one_batch_X]):\n",
    "            sep = np.zeros_like(x[:, :, ::5])\n",
    "            plot_semantic(np.concatenate([x, sep, preds[j]], axis=2))\n",
    "\n",
    "        plot_semantic(np.concatenate([one_batch_Y[0:1], sep, preds[4]], axis=2))\n",
    "        plot_semantic(np.concatenate([one_batch_Y[0:1], sep, preds[5]], axis=2))\n",
    "        \n",
    "        print('\\n#### episodes = {} #### (sweep: {})'.format(episodes, sweep))\n",
    "\n",
    "        history = alternative_multi_model.fit_generator(\n",
    "            train_gen,\n",
    "            steps_per_epoch=X[0].shape[-1] // BATCH_SIZE // 10,\n",
    "            epochs=50,\n",
    "            validation_data=valid_gen,\n",
    "            validation_steps=X_val[0].shape[-1] // BATCH_SIZE // 2,\n",
    "            verbose=1,\n",
    "            callbacks=[early_stopping],\n",
    "        )\n",
    "        \n",
    "        histories.append(history.history)\n",
    "        \n",
    "    val_loss = history.history['val_reconstruction_loss'][-(patience+1)]\n",
    "    model_filename = 'models/alternative_multi_model__sweep={}_decimation={}_numclasses={}_valloss={:.3f}.h5'.format(sweep, DECIMATION, len(CLASSES_NAMES), val_loss)\n",
    "    alternative_multi_model.save(model_filename)\n",
    "    histories_filename = 'histories/alternative_multi_model__sweep={}_decimation={}_numclasses={}_valloss={:.3f}.pkl'.format(sweep, DECIMATION, len(CLASSES_NAMES), val_loss)\n",
    "    with open(histories_filename, 'wb') as output:\n",
    "        pickle.dump(histories, output)\n",
    "        \n",
    "    print('Metrics on one valid batch:')\n",
    "    x_y, _ = next(valid_gen)\n",
    "    one_batch_X, one_batch_Y = x_y[:4], x_y[4]\n",
    "    preds = alternative_multi_model.predict(one_batch_X + [one_batch_Y])\n",
    "    for class_idx, class_names in enumerate(CLASSES_NAMES):\n",
    "        print('\\nClasses: {}'.format(class_names))\n",
    "        class_true = one_batch_Y[..., class_idx].flatten()\n",
    "        class_pred = preds[5][..., class_idx].flatten()\n",
    "        auc_score = roc_auc_score(class_true, class_pred)\n",
    "        print('---> ROC AUC score: {:.1f}'.format(100*auc_score))\n",
    "        print('---> class_pred.mean() / (class_true.mean() + 1e-10): {:.2f}'.format(class_pred.mean() / (1e-10 + class_true.mean())))\n",
    "\n",
    "    for racetrack in ['Town01', 'Town02']:\n",
    "        for episode in validation_episodes_for_movies:\n",
    "            make_movie(\n",
    "                model_filename,\n",
    "                racetrack,\n",
    "                episode,\n",
    "                DECIMATION,\n",
    "                CLASSES_NAMES,\n",
    "                CAMERA_IDS,\n",
    "                alternative_multi_model,\n",
    "                batch_size=BATCH_SIZE,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
